{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNg+z9kWLK9H2y1rZje47cH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancescoRosi01/Tesi/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "2xv30Ak4auDd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clona la repo con i dataset\n",
        "# i dataset sono in ./Tesi/datasets/\n",
        "# il primo dataset è ./Tesi/datasets/ds\n",
        "!git clone https://github.com/FrancescoRosi01/Tesi.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6aOUVX_aw69",
        "outputId": "b61f3e4b-5f7d-42d1-8824-0d328e05e6d3"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Tesi' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_image(path, label):\n",
        "    \"\"\" restituisce il tensore 3d (l'immagine) e la label associata al path che prende in input\"\"\"\n",
        "    img_raw = tf.io.read_file(path)\n",
        "    img = tf.io.decode_png(img_raw, channels=3)\n",
        "    img = tf.image.resize(img, (224,224))\n",
        "    # normalizzare\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "def load_ds(ds_path : Path):\n",
        "    \"\"\" restituisce i dataset di training, validation e test\"\"\"\n",
        "    imgs_path = ds_path / 'images'\n",
        "    labels_path = ds_path / 'labels' / 'labels.json'\n",
        "    with open(labels_path, 'r') as f:\n",
        "        labels = json.load(f)\n",
        "        labels = np.array(list(labels.values()))\n",
        "        labels = labels.astype(np.float32)\n",
        "    regex = re.compile(r\"img_(\\d+)\\.png\")\n",
        "    # imgs_path è una lista ordinata di path delle immagini.\n",
        "    imgs_path = sorted(\n",
        "        map(lambda x:str(x),imgs_path.glob('img_*.png')),\n",
        "        key=lambda x: int(regex.search(x).group(1))\n",
        "        )\n",
        "    train_paths, test_paths, train_labels, test_labels = train_test_split(imgs_path, labels, test_size=0.2, random_state=1)\n",
        "    train_paths, val_paths, train_labels, val_labels = train_test_split(train_paths, train_labels, test_size=0.25, random_state=1)\n",
        "    # train -> 60%, val -> 20%, test -> 20%\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices((train_paths,train_labels))\n",
        "    val_ds = tf.data.Dataset.from_tensor_slices((val_paths,val_labels))\n",
        "    test_ds = tf.data.Dataset.from_tensor_slices((test_paths,test_labels))\n",
        "    BATCH_SZ = 32\n",
        "    # load_and_process_image restituisce il tensore 3d (l'immagine) associata al path che prende in input\n",
        "    train_ds = train_ds.map(load_and_process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    val_ds = val_ds.map(load_and_process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    test_ds = test_ds.map(load_and_process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    # Shuffle\n",
        "    train_ds = train_ds.shuffle(buffer_size=1000)\n",
        "    val_ds = val_ds.shuffle(buffer_size=1000)\n",
        "    # Batch\n",
        "    train_ds = train_ds.batch(BATCH_SZ)\n",
        "    val_ds = val_ds.batch(BATCH_SZ)\n",
        "    test_ds = test_ds.batch(BATCH_SZ)\n",
        "    train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    val_ds = val_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    test_ds = test_ds.prefetch(buffer_size= tf.data.AUTOTUNE)\n",
        "    return train_ds,val_ds,test_ds"
      ],
      "metadata": {
        "id": "AfyF7ixMa700"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train,val,test = load_ds(Path(\"Tesi/datasets/ds\"))"
      ],
      "metadata": {
        "id": "r735ND3PbBxH"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train.take(1):\n",
        "    print(f\"Image batch shape: {images.shape}\")\n",
        "    print(f\"Label batch shape: {labels.shape}\")\n",
        "    print(f\"Sample label: {labels[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teDf9yh0bIYK",
        "outputId": "2037ff34-e138-4a2f-88a8-32985fee2f5f"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch shape: (32, 224, 224, 3)\n",
            "Label batch shape: (32,)\n",
            "Sample label: 0.24444444477558136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=(224,224,3)),\n",
        "\n",
        "    keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activation='relu',kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    # tanh come attivazione finale perchè resituisce valori tra -1 e 1\n",
        "    keras.layers.Dense(1, activation='tanh')\n",
        "    ])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',\n",
        "    metrics=['mae'],\n",
        ")"
      ],
      "metadata": {
        "id": "YAeSQ7mibME7"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# su CPU Colab il training per il primo ds dura circa 5 min\n",
        "history = model.fit(\n",
        "    train,\n",
        "    epochs = 10,\n",
        "    validation_data = val,\n",
        "    callbacks=[keras.callbacks.EarlyStopping(patience=5,restore_best_weights=True)]\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nnD26J8bY-g",
        "outputId": "f690fd22-8576-4d79-9eea-09a08edde5a4"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - loss: 0.3478 - mae: 0.4589 - val_loss: 0.0413 - val_mae: 0.1691\n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - loss: 0.0479 - mae: 0.1739 - val_loss: 0.0129 - val_mae: 0.0891\n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - loss: 0.0175 - mae: 0.1053 - val_loss: 0.0066 - val_mae: 0.0650\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - loss: 0.0168 - mae: 0.0953 - val_loss: 0.0052 - val_mae: 0.0613\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - loss: 0.0116 - mae: 0.0849 - val_loss: 0.0029 - val_mae: 0.0442\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 0.0107 - mae: 0.0784 - val_loss: 0.0023 - val_mae: 0.0394\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 0.0090 - mae: 0.0695 - val_loss: 0.0028 - val_mae: 0.0428\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - loss: 0.0124 - mae: 0.0857 - val_loss: 0.0032 - val_mae: 0.0468\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - loss: 0.0101 - mae: 0.0734 - val_loss: 0.0023 - val_mae: 0.0377\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - loss: 0.0082 - mae: 0.0708 - val_loss: 0.0018 - val_mae: 0.0347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa-iODt3bduH",
        "outputId": "a1039b77-e201-4dc1-958b-228658ee36e7"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 559ms/step - loss: 0.0029 - mae: 0.0430\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.002505873329937458, 0.039590172469615936]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si vede che il modello performa bene quando\n",
        "\n",
        "\n",
        "1.   le immagini hanno sfondo nero e linea bianca\n",
        "2.   l'offset è nel range -90, -90\n",
        "\n",
        "il punto 1 è abbastanza comprensibile dato che il modello è stato addestrato solo su immagini con background nero e linea bianca.\n",
        "\n"
      ],
      "metadata": {
        "id": "_z9v_b3g0XEu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zmo7WcAlLzYf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}